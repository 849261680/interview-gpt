#!/usr/bin/env python3
"""
PDFç®€å†APIæµ‹è¯•
é€šè¿‡HTTP APIæµ‹è¯•PDFç®€å†ä¸Šä¼ å’Œå¤„ç†
"""

import requests
import os
import logging
from pathlib import Path
import sqlite3

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_existing_pdf():
    """è·å–ç°æœ‰çš„PDFæ–‡ä»¶"""
    upload_dir = Path("backend/uploads/resumes")
    if upload_dir.exists():
        pdf_files = list(upload_dir.glob("*.pdf"))
        if pdf_files:
            return str(pdf_files[0])
    return None

def check_database_content(interview_id):
    """æ£€æŸ¥æ•°æ®åº“ä¸­çš„ç®€å†å†…å®¹"""
    try:
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®åº“è·¯å¾„
        db_paths = [
            'backend/interview_gpt.db',
            'interview_gpt.db',
            'backend/src/interview_gpt.db'
        ]
        
        conn = None
        for db_path in db_paths:
            if os.path.exists(db_path):
                conn = sqlite3.connect(db_path)
                logger.info(f"ğŸ“ ä½¿ç”¨æ•°æ®åº“: {db_path}")
                break
        
        if not conn:
            logger.error("âŒ æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶")
            return False
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT resume_context, resume_path FROM interviews WHERE id = ?",
            (interview_id,)
        )
        result = cursor.fetchone()
        
        if result:
            resume_context, resume_path = result
            logger.info(f"ğŸ“„ æ•°æ®åº“ä¸­çš„ç®€å†è·¯å¾„: {resume_path}")
            logger.info(f"ğŸ“ æ•°æ®åº“ä¸­çš„ç®€å†å†…å®¹é•¿åº¦: {len(resume_context) if resume_context else 0} å­—ç¬¦")
            
            if resume_context:
                logger.info(f"ğŸ“„ ç®€å†å†…å®¹é¢„è§ˆ: {resume_context[:200]}...")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«PDFäºŒè¿›åˆ¶æ ‡è¯†
                if '%PDF-' in resume_context or 'stream' in resume_context:
                    logger.error("âŒ æ•°æ®åº“ä¸­çš„ç®€å†å†…å®¹åŒ…å«PDFäºŒè¿›åˆ¶æ ‡è¯†!")
                    return False
                else:
                    logger.info("âœ… æ•°æ®åº“ä¸­çš„ç®€å†å†…å®¹ä¸ºçº¯æ–‡æœ¬")
                    return True
            else:
                logger.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰ç®€å†å†…å®¹")
                return False
        else:
            logger.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°é¢è¯•è®°å½•")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
        return False
    finally:
        conn.close()

def test_pdf_upload_api():
    """æµ‹è¯•PDFä¸Šä¼ API"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•PDFç®€å†ä¸Šä¼ API")
    
    # è·å–ç°æœ‰PDFæ–‡ä»¶
    pdf_path = get_existing_pdf()
    if not pdf_path:
        logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„PDFæ–‡ä»¶è¿›è¡Œæµ‹è¯•")
        return False
    
    logger.info(f"ğŸ“„ ä½¿ç”¨PDFæ–‡ä»¶: {pdf_path}")
    
    try:
        # å‡†å¤‡APIè¯·æ±‚
        url = "http://localhost:8000/api/interviews/"
        
        # å‡†å¤‡è¡¨å•æ•°æ®
        data = {
            'position': 'AIåº”ç”¨å·¥ç¨‹å¸ˆ',
            'difficulty': 'medium'
        }
        
        # å‡†å¤‡æ–‡ä»¶
        with open(pdf_path, 'rb') as f:
            files = {
                'resume': (os.path.basename(pdf_path), f, 'application/pdf')
            }
            
            # å‘é€è¯·æ±‚
            logger.info("ğŸ“¤ å‘é€APIè¯·æ±‚...")
            response = requests.post(url, data=data, files=files)
        
        # æ£€æŸ¥å“åº”
        if response.status_code == 200:
            result = response.json()
            interview_id = result.get('id')
            logger.info(f"âœ… APIè¯·æ±‚æˆåŠŸ: é¢è¯•ID={interview_id}")
            
            # æ£€æŸ¥æ•°æ®åº“å†…å®¹
            logger.info("ğŸ” æ£€æŸ¥æ•°æ®åº“ä¸­çš„ç®€å†å†…å®¹...")
            db_success = check_database_content(interview_id)
            
            if db_success:
                logger.info("ğŸ‰ PDFç®€å†ä¸Šä¼ å’Œè§£ææˆåŠŸ!")
                return True
            else:
                logger.error("âŒ æ•°æ®åº“ä¸­çš„ç®€å†å†…å®¹æœ‰é—®é¢˜")
                return False
        else:
            logger.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except requests.exceptions.ConnectionError:
        logger.error("âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ï¼Œè¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

def test_binary_vs_text_comparison():
    """æµ‹è¯•äºŒè¿›åˆ¶å†…å®¹ä¸æ–‡æœ¬å†…å®¹çš„å¯¹æ¯”"""
    logger.info("ğŸ” æµ‹è¯•äºŒè¿›åˆ¶å†…å®¹ä¸æ–‡æœ¬å†…å®¹çš„å¯¹æ¯”...")
    
    pdf_path = get_existing_pdf()
    if not pdf_path:
        logger.warning("âš ï¸ æ²¡æœ‰PDFæ–‡ä»¶è¿›è¡Œå¯¹æ¯”æµ‹è¯•")
        return
    
    try:
        # è¯»å–PDFäºŒè¿›åˆ¶å†…å®¹ï¼ˆé”™è¯¯çš„æ–¹å¼ï¼‰
        with open(pdf_path, 'rb') as f:
            binary_content = f.read()
        
        # å°è¯•ç›´æ¥è§£ç ï¼ˆä¹‹å‰çš„é”™è¯¯åšæ³•ï¼‰
        try:
            wrong_decoded = binary_content.decode('utf-8', errors='ignore')
            logger.info("âŒ é”™è¯¯æ–¹å¼ï¼ˆç›´æ¥è§£ç PDFäºŒè¿›åˆ¶ï¼‰:")
            logger.info(f"   å†…å®¹é•¿åº¦: {len(wrong_decoded)} å­—ç¬¦")
            logger.info(f"   å†…å®¹é¢„è§ˆ: {wrong_decoded[:100]}...")
            logger.info(f"   åŒ…å«PDFæ ‡è¯†: {'%PDF-' in wrong_decoded}")
            logger.info(f"   ä¼šå¯¼è‡´APIé”™è¯¯: {'æ˜¯' if '%PDF-' in wrong_decoded else 'å¦'}")
        except Exception as e:
            logger.error(f"âŒ ç›´æ¥è§£ç å¤±è´¥: {e}")
        
        # ä½¿ç”¨æ­£ç¡®çš„æ–¹å¼ï¼ˆPDFè§£æå™¨ï¼‰
        import sys
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend', 'src'))
        from services.resume_parser import resume_parser
        
        result = resume_parser.parse_resume(pdf_path)
        if result.get('success', False):
            correct_content = result.get('raw_text', '')
            logger.info("âœ… æ­£ç¡®æ–¹å¼ï¼ˆPDFè§£æå™¨ï¼‰:")
            logger.info(f"   å†…å®¹é•¿åº¦: {len(correct_content)} å­—ç¬¦")
            logger.info(f"   å†…å®¹é¢„è§ˆ: {correct_content[:100]}...")
            logger.info(f"   åŒ…å«PDFæ ‡è¯†: {'%PDF-' in correct_content}")
            logger.info(f"   ä¼šå¯¼è‡´APIé”™è¯¯: {'å¦' if '%PDF-' not in correct_content else 'æ˜¯'}")
        else:
            logger.error(f"âŒ PDFè§£æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        logger.error(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹PDFç®€å†APIä¿®å¤æµ‹è¯•")
    
    # æµ‹è¯•1: APIä¸Šä¼ æµ‹è¯•
    logger.info("\n" + "="*50)
    logger.info("æµ‹è¯•1: PDFç®€å†APIä¸Šä¼ æµ‹è¯•")
    logger.info("="*50)
    success1 = test_pdf_upload_api()
    
    # æµ‹è¯•2: äºŒè¿›åˆ¶vsæ–‡æœ¬å¯¹æ¯”
    logger.info("\n" + "="*50)
    logger.info("æµ‹è¯•2: äºŒè¿›åˆ¶vsæ–‡æœ¬å†…å®¹å¯¹æ¯”")
    logger.info("="*50)
    test_binary_vs_text_comparison()
    
    # æ€»ç»“
    logger.info("\n" + "="*50)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("="*50)
    if success1:
        logger.info("âœ… PDFç®€å†APIä¿®å¤æˆåŠŸ!")
        logger.info("âœ… ä¿®å¤æ•ˆæœ:")
        logger.info("   1. PDFæ–‡ä»¶æ­£ç¡®è§£æä¸ºæ–‡æœ¬å†…å®¹")
        logger.info("   2. æ•°æ®åº“ä¸­å­˜å‚¨çš„æ˜¯çº¯æ–‡æœ¬ï¼Œä¸æ˜¯äºŒè¿›åˆ¶")
        logger.info("   3. DeepSeek APIå°†æ¥æ”¶åˆ°å¯è¯»çš„æ–‡æœ¬å†…å®¹")
        logger.info("   4. ä¸å†å‡ºç°HTTP 400 Bad Requesté”™è¯¯")
        logger.info("âœ… ç”¨æˆ·å¯ä»¥æ­£å¸¸ä¸Šä¼ PDFç®€å†è¿›è¡ŒAIé¢è¯•!")
    else:
        logger.error("âŒ PDFç®€å†APIä»æœ‰é—®é¢˜")
        logger.error("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        logger.error("   1. åç«¯æœåŠ¡æœªå¯åŠ¨")
        logger.error("   2. PDFè§£æå™¨é…ç½®é—®é¢˜")
        logger.error("   3. æ•°æ®åº“è¿æ¥é—®é¢˜")
    
    return success1

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 